{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BSU Transit System Weather Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load in our packages and read our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from plotly import tools\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data set that will represent the majority of the data\n",
    "df = pd.DataFrame(pd.read_csv(\"entries.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date, time, and timestamp columns\n",
    "df[['date','time']] = df.timestamp.str.split(expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add month, day, and day of year columns\n",
    "df['Month']=df['date'].dt.month_name()\n",
    "df['day'] = pd.DatetimeIndex(df['date']).day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in all other data sets from our shuttle data\n",
    "mapping = pd.DataFrame(pd.read_csv(\"stop_loop_mapping.csv\"))\n",
    "buses = pd.DataFrame(pd.read_csv(\"buses.csv\"))\n",
    "loops = pd.DataFrame(pd.read_csv(\"loops.csv\"))\n",
    "stops = pd.DataFrame(pd.read_csv(\"stops.csv\"))\n",
    "users = pd.DataFrame(pd.read_csv(\"users.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index values for replacement\n",
    "stops.set_index('id')['stop_name']\n",
    "loops.set_index('id')['loop_name']\n",
    "buses.set_index('id')['bus_number']\n",
    "'Indexed!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace ID values with names for categorical data\n",
    "df['stop_id'] = df['stop_id'].replace(stops.set_index('id')['stop_name'])\n",
    "df['loop_id'] = df['loop_id'].replace(loops.set_index('id')['loop_name'])\n",
    "df['bus_id'] = df['bus_id'].replace(buses.set_index('id')['bus_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up column titles and examine current state of main data set\n",
    "df.rename(columns={'stop_id':'Stop ID','boarded':'Students Boarded',\n",
    "                   'loop_name':'Loop Name', 'loop_id':'Loop ID',\n",
    "                   'driver_id':'Driver ID','id':'ID', 'bus_id':'Bus ID',\n",
    "                   'left_behind':'Students Left Behind',\n",
    "                   'time':'Time', 'month':'Month', 'day':'Day',\n",
    "                   'day_of_year':'Day of Year', 'hour':'Hour'}, inplace=True)\n",
    "df.drop(['is_deleted'], inplace=True, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate shuttle data by day\n",
    "day_df = df.groupby(['date','Loop ID']).agg({'Students Boarded': ['mean', 'sum'],\n",
    "                                        'Students Left Behind': 'sum'})\n",
    "day_df.columns = ['Mean Students Boarded', 'Total Students Boarded', 'Total Students Left Behind']\n",
    "day_df = day_df.reset_index()\n",
    "day_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure categorical data is treated as such\n",
    "for col in ['Stop ID', 'Loop ID', 'Bus ID']:\n",
    "    df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types for each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in weather data to begin cleaning it\n",
    "weather_df = pd.read_csv(\"https://raw.githubusercontent.com/kaberry2/DSCI689/main/datasets/muncie_weather.csv\")\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and grouping dates within weather data\n",
    "weather_df['timestamp'] = pd.to_datetime(weather_df['dt'], unit = 's')\n",
    "weather_df['hour'] = pd.DatetimeIndex(weather_df['timestamp']).hour\n",
    "weather_df['date'] = pd.DatetimeIndex(weather_df['timestamp']).date\n",
    "weather_df.loc[:, ['hour', 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from Kelvin to Fahrenheit\n",
    "weather_df['temp'] = (weather_df['temp']-273.15)*1.8 + 32\n",
    "weather_df['rain_1h'] = weather_df['rain_1h']/2.54\n",
    "weather_df['rain_3h'] = weather_df['rain_3h']/2.54\n",
    "weather_df['snow_1h'] = weather_df['snow_1h']/2.54\n",
    "weather_df['snow_3h'] = weather_df['snow_3h']/2.54\n",
    "weather_df['wind_speed'] = weather_df['wind_speed']*2.237"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group based on established aggregation of day\n",
    "aggregated_weather_df = weather_df.groupby('date').agg({'temp': ['mean', 'min', 'max'],\n",
    "                                                       'humidity': 'mean',\n",
    "                                                       'wind_speed': 'mean',\n",
    "                                                       'rain_1h': 'median',\n",
    "                                                       'rain_3h': 'median',\n",
    "                                                       'snow_1h': 'median',\n",
    "                                                       'snow_3h': 'median'})\n",
    "\n",
    "aggregated_weather_df.columns = ['temp_mean', 'temp_min', 'temp_max', 'humidity_mean', 'wind_speed_mean', \n",
    "                                'rain_1h_median', 'rain_3h_median', 'snow_1h_median', 'snow_3h_median']\n",
    "\n",
    "aggregated_weather_df = aggregated_weather_df.reset_index()\n",
    "aggregated_weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as a new data set\n",
    "path = Path(\"C:/Users/kimbe/Documents/School/Spring 2022/DSCI 689/HW 1/agg_weather.csv\")\n",
    "path.parent.mkdir(parents = True, exist_ok = True)\n",
    "aggregated_weather_df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in cleaned weather data set after it was uploaded to github shared space\n",
    "weather = pd.read_csv(\"agg_weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['date'] = pd.to_datetime(weather['date'])\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_df['date'] = pd.to_datetime(day_df['date'])\n",
    "\n",
    "merged_df = day_df.merge(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df = pd.merge(day_df, weather, how='outer', on = 'date')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.drop(['Unnamed: 0'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up column titles and examine current state of main data set\n",
    "merged_df.rename(columns={'date':'Date','temp_mean':'Temp Mean','temp_min':'Temp Low',\n",
    "                          'temp_max':'Temp High', 'humidity_mean':'Humidity Mean',\n",
    "                          'wind_speed_mean':'Wind Speed Mean','rain_1h_median':'Rain One Hour Median',\n",
    "                          'rain_3h_median':'Rain Three Hour Median', 'snow_1h_median':'Snow One Hour Median',\n",
    "                          'snow_3h_median':'Snow Three Hour Median'}, inplace=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged_df\n",
    "df['Month']=df['Date'].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Season']=np.where((df['Month'].isin(['December','January','February'])), 'Winter',\n",
    "                                    np.where((df['Month'].isin(['March','April','May'])), 'Spring',\n",
    "                                              np.where((df['Month'].isin(['June','July','August'])),'Summer',\n",
    "                                                       np.where((df['Month'].isin(['September','October','November'])),'Fall',\n",
    "                                                               'Other'))))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as a new data set\n",
    "path = Path(\"C:/Users/kimbe/Documents/School/Spring 2022/DSCI 689/HW 1/merged_df.csv\")\n",
    "path.parent.mkdir(parents = True, exist_ok = True)\n",
    "df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_sum = df['Total Students Boarded'].groupby([df['Loop ID']]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_set = ['0.80','0.60','0.40','0.20']\n",
    "loop_sum.plot.pie(normalize=True, autopct='%1.1f%%', colors=color_set)\n",
    "# From this graph we can see the Demand Response loop is the least busy loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_sum = df['Total Students Boarded'].groupby([df['Season']]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_set = ['0.80','0.60','0.40','0.20']\n",
    "season_sum.plot.pie(normalize=True, autopct='%1.1f%%', colors=color_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we can see that the fall 2021 semester was more than twice as busy as the spring 2021 semester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_by_day = df.groupby([\"Date\", \"Temp High\"])[\"Total Students Boarded\"].mean()\n",
    "loop_by_day = pd.DataFrame(loop_by_day)\n",
    "loop_by_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_by_day.sort_values(\"Total Students Boarded\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scaling the data for a better visualization\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaled_mean_students = preprocessing.scale(merged_df['Mean Students Boarded'])\n",
    "scaled_mean_temp = preprocessing.scale(merged_df['Temp Mean'])\n",
    "scaled_1h_rain = preprocessing.scale(merged_df['Rain One Hour Median'])\n",
    "scaled_1h_snow = preprocessing.scale(merged_df['Snow One Hour Median'])\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(name = \"Mean Students Boarded\", x = merged_df[\"date\"], y = scaled_mean_students, mode = \"markers\"))\n",
    "fig.add_trace(go.Scatter(name = \"Mean Temperature\", x = merged_df[\"date\"], y = scaled_mean_temp, mode = \"markers\"))\n",
    "fig.add_trace(go.Scatter(name = \"Rain One Hour Median\", x = merged_df[\"date\"], y = scaled_1h_rain, mode = \"markers\"))\n",
    "fig.add_trace(go.Scatter(name = \"Snow One Hour Median\", x = merged_df[\"date\"], y = scaled_1h_snow, mode = \"markers\"))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = px.scatter(merged_loop_df, x = \"date\", y = \"Total Students Boarded\", color = \"Loop ID\")\n",
    "\n",
    "fig2.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
